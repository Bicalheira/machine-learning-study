{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f2496d6",
   "metadata": {},
   "source": [
    "# Sintaxe básico do PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d28894",
   "metadata": {},
   "source": [
    "Assim como o NumPy, o PyTorch é uma biblioteca de processamento vetorial/matroarcaç/tensorial. Operações sobre os tensores do PyTorch possuem sintaxe consideravelmente parecida com operações sobre tensores do Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5836afb3",
   "metadata": {},
   "source": [
    "## Tipos de tensores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192875ad",
   "metadata": {},
   "source": [
    "Você pode criar tensores do PyTorch de inúmeras formas! Vamos ver primeiro os tipos de tensores que estão ao nosso dispor. Para isso, vamos converter listas comuns do **Python** em tensors do PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a58c7966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "[[1, 2, 3], [4, 5, 6]]\n",
      "\n",
      "torch.float32\n",
      "[[1, 2, 3], [4, 5, 6]]\n",
      "\n",
      "torch.float64\n",
      "[[1, 2, 3], [4, 5, 6]]\n",
      "\n",
      "torch.int64\n",
      "[[1, 2, 3], [4, 5, 6]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "list = [[1, 2, 3], [4, 5, 6]]\n",
    "\n",
    "tensor = torch.Tensor(list)\n",
    "\n",
    "print(tensor.dtype)\n",
    "print(list)\n",
    "print(\"\")\n",
    "\n",
    "tensor = torch.FloatTensor(list)\n",
    "\n",
    "print(tensor.dtype)\n",
    "print(list)\n",
    "print(\"\")\n",
    "\n",
    "tensor = torch.DoubleTensor(list)\n",
    "\n",
    "print(tensor.dtype)\n",
    "print(list)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "tensor = torch.LongTensor(list)\n",
    "\n",
    "print(tensor.dtype)\n",
    "print(list)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f29bfa",
   "metadata": {},
   "source": [
    "## Outras formas de instanciar tensores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a129d3ca",
   "metadata": {},
   "source": [
    "### A partir de arrays Numpy\n",
    "\n",
    "__*torch.from_numpy()*__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22909166",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.60294106 0.97366661 0.04129556 0.50940772]\n",
      " [0.09029864 0.67343186 0.47052895 0.18655834]\n",
      " [0.95244386 0.32086876 0.24397609 0.65128376]]\n",
      "float64\n",
      "\n",
      "tensor([[0.6029, 0.9737, 0.0413, 0.5094],\n",
      "        [0.0903, 0.6734, 0.4705, 0.1866],\n",
      "        [0.9524, 0.3209, 0.2440, 0.6513]], dtype=torch.float64)\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "array = np.random.rand(3, 4)\n",
    "\n",
    "tensor = torch.from_numpy(array)\n",
    "\n",
    "print(array)\n",
    "print(array.dtype)\n",
    "print(\"\")\n",
    "print(tensor)\n",
    "print(tensor.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19346531",
   "metadata": {},
   "source": [
    "### Tensores inicializados\n",
    "\n",
    "Essas funções recebem como parâmetro o tamanho de cada dimensão do tensor. Aqui vamos conhecer as seguintes funções:\n",
    "\n",
    "\n",
    "__*torch.ones()*__ => Cria um tensor preenchido com zeros.\n",
    "\n",
    "__*torch.zeros()*__ => Cria um tensor preenchido com uns.\n",
    "\n",
    "__*torch.randn()*__ => Cria um tensor preencido com números aleatórios a partir de uma distribuição normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfb19858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "tensor([[ 0.7343,  0.3146,  0.8961],\n",
      "        [ 0.1550,  0.3605, -1.7047],\n",
      "        [-1.0968,  0.8590,  0.2687]])\n"
     ]
    }
   ],
   "source": [
    "tensor1 = torch.ones(2, 3)\n",
    "tensor0 = torch.zeros(4, 5)\n",
    "tensorRand = torch.randn(3, 3)\n",
    "\n",
    "print(tensor1)\n",
    "print(tensor0)\n",
    "print(tensorRand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e52939",
   "metadata": {},
   "source": [
    "### Tensor para um array numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d006b1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "array = tensor.data.numpy()\n",
    "\n",
    "print(type(tensor))\n",
    "print(type(array))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a1c6f6",
   "metadata": {},
   "source": [
    "### Indexação\n",
    "\n",
    "De posse dessa informação, a indexação é feita de forma similar a arrays Numpy, através da sintaxe de conchetes []."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "561a54e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0.7343,   0.3146, -10.0000],\n",
      "        [  0.1550,   0.3605,  -1.7047],\n",
      "        [ -1.0968,   0.8590,   0.2687]])\n",
      "\n",
      "tensor([[  0.7343,   0.3146, -10.0000],\n",
      "        [  0.1550,   0.3605,  -1.7047],\n",
      "        [ -1.0968,   0.8590,   0.2687]])\n",
      "\n",
      "tensor([[  0.7343,   0.3146, -10.0000],\n",
      "        [  0.1550,   0.3605,  -1.7047]])\n",
      "\n",
      "tensor([-10.0000,  -1.7047,   0.2687])\n",
      "\n",
      "tensor(-10.)\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "print(tensorRand)\n",
    "print(\"\")\n",
    "\n",
    "tensorRand[0, 2] = - 10\n",
    "\n",
    "print(tensorRand)\n",
    "print(\"\")\n",
    "\n",
    "print(tensorRand[0:2])\n",
    "print(\"\")\n",
    "print(tensorRand[:, 2])\n",
    "print(\"\")\n",
    "print(tensorRand[0, 2])\n",
    "print(tensorRand[0, 2].size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a550a6b6",
   "metadata": {},
   "source": [
    "### Operações com tensores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ac5aef",
   "metadata": {},
   "source": [
    "A função .item() utilizada anteriormente extrai o número de um tensor que possui um único valor, permitindo realizar operações numéricas do Python.\n",
    "\n",
    "Vale ressaltar tambpem que operações entre tensores são realizados ponto a ponto, operando cada elemente (i, j) do tensor t1, com o elemento (i, j) do tensor t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3013773e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0.7343,   0.3146, -10.0000],\n",
      "        [  0.1550,   0.3605,  -1.7047]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[-8.9511, -8.9511],\n",
      "        [-1.1892, -1.1892]])\n"
     ]
    }
   ],
   "source": [
    "# tensor = tensorRand[0:2, :]\n",
    "\n",
    "print(tensor)\n",
    "print(tensor1)\n",
    "\n",
    "print(torch.mm(tensor, tensor1.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e2335b",
   "metadata": {},
   "source": [
    "### Função .size() e .view()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865f15f4",
   "metadata": {},
   "source": [
    "Uma operação **importantíssima** na manipulação de tensores para Deep Learning é a reorganização das suas dimensções, Dessa forma podemos, por exemplo, **linearizar um tensor n-dimensional**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c06474d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0656, -0.0189, -0.7643],\n",
      "         [ 0.1161,  0.6317, -1.2649]],\n",
      "\n",
      "        [[-1.1579,  1.0589,  0.1476],\n",
      "         [-1.5816, -0.0884,  2.5035]]])\n",
      "\n",
      "torch.Size([2, 2, 3])\n",
      "\n",
      "torch.Size([12])\n",
      "tensor([-0.0656, -0.0189, -0.7643,  0.1161,  0.6317, -1.2649, -1.1579,  1.0589,\n",
      "         0.1476, -1.5816, -0.0884,  2.5035])\n",
      "\n",
      "torch.Size([4, 3])\n",
      "tensor([[-0.0656, -0.0189, -0.7643],\n",
      "        [ 0.1161,  0.6317, -1.2649],\n",
      "        [-1.1579,  1.0589,  0.1476],\n",
      "        [-1.5816, -0.0884,  2.5035]])\n",
      "\n",
      "torch.Size([2, 6])\n",
      "tensor([[-0.0656, -0.0189, -0.7643,  0.1161,  0.6317, -1.2649],\n",
      "        [-1.1579,  1.0589,  0.1476, -1.5816, -0.0884,  2.5035]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.randn(2, 2, 3)\n",
    "\n",
    "print(tensor)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(tensor.size())\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "tensor = tensor.view(12)\n",
    "print(tensor.size())\n",
    "print(tensor)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "tensor = tensor.view(4, 3)\n",
    "print(tensor.size())\n",
    "print(tensor)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "tensor = tensor.view(2, 2, 3 )\n",
    "tensor = tensor.view(tensor.size(0), -1)\n",
    "print(tensor.size())\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f87718",
   "metadata": {},
   "source": [
    "###  GPU Cast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4b1876",
   "metadata": {},
   "source": [
    "para que o seu script dê suporte a infraestrutura com e sem GPU, é importante definir o dispositivo no início do seu código de acordo com a verificação apresentada a seguir. Essa definição será utilizada toda vez que precisarmos subir os valores na GPU, como os pesos da rede, os gradientes e etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "73f0ebca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "tensor([ 0.7854, -0.5989,  0.6153,  1.8983, -0.6095,  0.4376, -1.5621,  0.0246,\n",
      "         0.2784, -0.3381], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "tensor = torch.randn(10)\n",
    "tensor = tensor.to(device)\n",
    "    \n",
    "print(device)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5cc866",
   "metadata": {},
   "source": [
    "### Atividade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb761c1",
   "metadata": {},
   "source": [
    "Pensando nisso, crie um tensor aleatório tns1 com a dimensionalidade 7 x 7 x 3 e um outro tensor aleatório tns2 de 147 x 1. Modificando apenas tns1 some os dois tensores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a6434a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4583],\n",
      "        [-0.9572],\n",
      "        [ 0.0732],\n",
      "        [ 1.8609],\n",
      "        [ 1.0095],\n",
      "        [-1.7584],\n",
      "        [-1.9615],\n",
      "        [-0.5258],\n",
      "        [-0.0541],\n",
      "        [-1.0323],\n",
      "        [-1.4489],\n",
      "        [-0.0241],\n",
      "        [ 0.8427],\n",
      "        [-1.4269],\n",
      "        [-0.3372],\n",
      "        [-1.9785],\n",
      "        [-0.8502],\n",
      "        [-0.1873],\n",
      "        [ 0.4898],\n",
      "        [ 1.2227],\n",
      "        [-0.5585],\n",
      "        [-0.7771],\n",
      "        [-0.7542],\n",
      "        [-0.5770],\n",
      "        [-2.0674],\n",
      "        [-0.7758],\n",
      "        [ 0.4291],\n",
      "        [ 0.0648],\n",
      "        [ 1.2425],\n",
      "        [ 0.4871],\n",
      "        [ 0.0556],\n",
      "        [ 0.9315],\n",
      "        [ 1.5464],\n",
      "        [ 1.3146],\n",
      "        [-0.4789],\n",
      "        [ 0.5943],\n",
      "        [-1.3614],\n",
      "        [ 2.3232],\n",
      "        [-0.7158],\n",
      "        [ 0.8363],\n",
      "        [ 0.8630],\n",
      "        [ 0.6128],\n",
      "        [-2.5583],\n",
      "        [-0.6894],\n",
      "        [ 0.4073],\n",
      "        [-0.6969],\n",
      "        [-1.2571],\n",
      "        [-0.8624],\n",
      "        [-0.9677],\n",
      "        [-1.5707],\n",
      "        [ 0.4641],\n",
      "        [ 0.5073],\n",
      "        [ 2.6032],\n",
      "        [-0.2250],\n",
      "        [-0.1005],\n",
      "        [ 0.1801],\n",
      "        [-0.1220],\n",
      "        [ 0.0331],\n",
      "        [-0.8747],\n",
      "        [-1.4143],\n",
      "        [ 0.2461],\n",
      "        [ 0.0941],\n",
      "        [ 0.5424],\n",
      "        [-1.5157],\n",
      "        [-1.9191],\n",
      "        [ 0.3907],\n",
      "        [-1.4136],\n",
      "        [-0.3699],\n",
      "        [-0.7959],\n",
      "        [-0.3882],\n",
      "        [-0.0862],\n",
      "        [ 1.2742],\n",
      "        [-1.6666],\n",
      "        [-0.2716],\n",
      "        [-1.7895],\n",
      "        [ 1.0967],\n",
      "        [-0.4131],\n",
      "        [ 1.6703],\n",
      "        [-0.2255],\n",
      "        [ 1.2583],\n",
      "        [ 0.1175],\n",
      "        [ 0.8238],\n",
      "        [ 0.1234],\n",
      "        [-0.3514],\n",
      "        [ 1.6808],\n",
      "        [-1.6376],\n",
      "        [-2.0196],\n",
      "        [-1.2482],\n",
      "        [ 1.2331],\n",
      "        [-1.1263],\n",
      "        [ 1.4168],\n",
      "        [-0.3598],\n",
      "        [ 1.1904],\n",
      "        [ 0.4331],\n",
      "        [ 0.2827],\n",
      "        [-1.5496],\n",
      "        [ 0.5708],\n",
      "        [ 0.4948],\n",
      "        [-1.6384],\n",
      "        [ 0.7181],\n",
      "        [ 0.1186],\n",
      "        [-0.3909],\n",
      "        [-0.5807],\n",
      "        [ 1.1398],\n",
      "        [-0.7666],\n",
      "        [ 0.5179],\n",
      "        [-0.9394],\n",
      "        [-0.6562],\n",
      "        [ 0.2315],\n",
      "        [ 1.4445],\n",
      "        [ 0.4798],\n",
      "        [-0.4449],\n",
      "        [ 0.5538],\n",
      "        [-0.0027],\n",
      "        [ 0.3154],\n",
      "        [-0.5493],\n",
      "        [-0.9711],\n",
      "        [ 0.8252],\n",
      "        [ 1.1650],\n",
      "        [-0.1848],\n",
      "        [ 0.2149],\n",
      "        [ 0.8544],\n",
      "        [ 1.5659],\n",
      "        [-0.1354],\n",
      "        [ 0.4877],\n",
      "        [-0.3812],\n",
      "        [-1.0627],\n",
      "        [ 0.9954],\n",
      "        [ 0.1850],\n",
      "        [ 0.2127],\n",
      "        [-1.5083],\n",
      "        [-1.1311],\n",
      "        [ 0.1904],\n",
      "        [ 0.7117],\n",
      "        [ 0.3501],\n",
      "        [ 0.4555],\n",
      "        [ 0.4473],\n",
      "        [-1.8659],\n",
      "        [-1.0468],\n",
      "        [ 1.8162],\n",
      "        [-0.1133],\n",
      "        [-0.4035],\n",
      "        [ 0.1496],\n",
      "        [-1.4834],\n",
      "        [-0.7250],\n",
      "        [ 1.2784],\n",
      "        [ 0.2429]])\n",
      "tensor([[ 0.3845],\n",
      "        [-0.2096],\n",
      "        [ 0.4862],\n",
      "        [ 2.8544],\n",
      "        [ 1.8583],\n",
      "        [-2.0203],\n",
      "        [-0.7302],\n",
      "        [-1.9125],\n",
      "        [ 1.1739],\n",
      "        [-0.9106],\n",
      "        [-1.7654],\n",
      "        [-1.2760],\n",
      "        [ 0.4168],\n",
      "        [-1.5578],\n",
      "        [ 0.1911],\n",
      "        [-1.0697],\n",
      "        [ 0.9098],\n",
      "        [ 0.3765],\n",
      "        [ 0.7249],\n",
      "        [ 0.4290],\n",
      "        [-0.9184],\n",
      "        [ 0.3395],\n",
      "        [-1.8614],\n",
      "        [ 0.6672],\n",
      "        [-1.7241],\n",
      "        [-1.3797],\n",
      "        [-0.4752],\n",
      "        [-0.4351],\n",
      "        [ 0.1334],\n",
      "        [ 1.5281],\n",
      "        [ 0.9824],\n",
      "        [ 2.1537],\n",
      "        [ 1.3968],\n",
      "        [ 2.6676],\n",
      "        [-0.9965],\n",
      "        [-1.1184],\n",
      "        [-0.1550],\n",
      "        [ 1.7061],\n",
      "        [-0.4301],\n",
      "        [-0.4988],\n",
      "        [ 3.0053],\n",
      "        [-0.3413],\n",
      "        [-3.3898],\n",
      "        [ 1.2636],\n",
      "        [-0.9522],\n",
      "        [-0.2302],\n",
      "        [-1.2082],\n",
      "        [-0.8536],\n",
      "        [ 1.3709],\n",
      "        [-2.0691],\n",
      "        [ 0.7589],\n",
      "        [-0.4221],\n",
      "        [ 2.8615],\n",
      "        [ 0.5031],\n",
      "        [-0.7230],\n",
      "        [-0.5933],\n",
      "        [-0.1867],\n",
      "        [-0.8530],\n",
      "        [-2.2289],\n",
      "        [-0.6418],\n",
      "        [ 0.2575],\n",
      "        [ 0.4870],\n",
      "        [ 2.0578],\n",
      "        [-1.2423],\n",
      "        [-2.2602],\n",
      "        [ 0.8775],\n",
      "        [-1.3749],\n",
      "        [ 1.1697],\n",
      "        [-1.4039],\n",
      "        [ 0.3652],\n",
      "        [ 1.1150],\n",
      "        [ 0.5740],\n",
      "        [-1.1798],\n",
      "        [ 1.1395],\n",
      "        [-1.9581],\n",
      "        [ 0.1747],\n",
      "        [-1.6120],\n",
      "        [ 0.3615],\n",
      "        [ 0.1578],\n",
      "        [-1.5006],\n",
      "        [-0.6938],\n",
      "        [ 0.5556],\n",
      "        [ 0.1568],\n",
      "        [-0.8135],\n",
      "        [ 0.5718],\n",
      "        [-2.6602],\n",
      "        [-2.7800],\n",
      "        [-0.8923],\n",
      "        [-0.3813],\n",
      "        [-1.0524],\n",
      "        [ 0.6837],\n",
      "        [ 0.7533],\n",
      "        [ 1.6342],\n",
      "        [-0.0184],\n",
      "        [ 0.7828],\n",
      "        [-1.5904],\n",
      "        [ 1.2018],\n",
      "        [ 0.5361],\n",
      "        [-1.5851],\n",
      "        [ 0.6986],\n",
      "        [ 1.3792],\n",
      "        [-2.0289],\n",
      "        [-0.8191],\n",
      "        [ 1.6389],\n",
      "        [-2.1030],\n",
      "        [ 0.9484],\n",
      "        [-0.6220],\n",
      "        [ 0.1123],\n",
      "        [ 0.5923],\n",
      "        [ 0.6728],\n",
      "        [ 0.7029],\n",
      "        [-0.5824],\n",
      "        [ 0.9084],\n",
      "        [ 1.0453],\n",
      "        [-0.3304],\n",
      "        [ 0.6559],\n",
      "        [-1.9691],\n",
      "        [ 1.3980],\n",
      "        [ 0.7420],\n",
      "        [-1.8790],\n",
      "        [-0.5136],\n",
      "        [ 0.2399],\n",
      "        [ 2.1555],\n",
      "        [-0.2707],\n",
      "        [-1.1528],\n",
      "        [ 0.5045],\n",
      "        [-1.1469],\n",
      "        [-0.6867],\n",
      "        [ 0.0667],\n",
      "        [ 0.6980],\n",
      "        [-1.0004],\n",
      "        [ 0.9884],\n",
      "        [-0.1144],\n",
      "        [ 1.7660],\n",
      "        [ 1.3701],\n",
      "        [-0.3094],\n",
      "        [ 1.9428],\n",
      "        [-3.8622],\n",
      "        [-2.6279],\n",
      "        [ 1.5892],\n",
      "        [-0.6824],\n",
      "        [-0.8758],\n",
      "        [ 1.4654],\n",
      "        [-2.1734],\n",
      "        [-2.7975],\n",
      "        [ 1.7657],\n",
      "        [ 0.6185]])\n"
     ]
    }
   ],
   "source": [
    "tensor1 = torch.randn(7, 7, 3)\n",
    "tensor2 = torch.randn(147, 1)\n",
    "\n",
    "tensor1 = tensor1.view(-1, 1)\n",
    "\n",
    "print(tensor1)\n",
    "\n",
    "print(tensor1 + tensor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2149cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
